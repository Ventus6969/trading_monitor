#!/usr/bin/env python3
"""
æ™ºèƒ½å®šæ™‚åŒæ­¥ - åªæœ‰æª¢æ¸¬åˆ°è®ŠåŒ–æ‰åŒæ­¥
å¯ä»¥ç¯€çœ90%ä»¥ä¸Šçš„æµé‡è²»ç”¨
"""
import os
import hashlib
import subprocess
import logging
from datetime import datetime
from data_sync import sync_database

# è¨­ç½®ç°¡å–®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

# é…ç½®æ–‡ä»¶
REMOTE_HOST = "15.168.60.229"
REMOTE_USER = "ec2-user"
REMOTE_DB_PATH = "/home/ec2-user/69trading/data/trading_signals.db"
SSH_KEY_PATH = os.path.expanduser("~/.ssh/trading_monitor")
HASH_FILE = 'data/.last_sync_hash'
STATS_FILE = 'data/.sync_stats'

def get_remote_file_info():
    """ç²å–é ç¨‹æ–‡ä»¶ä¿¡æ¯ï¼ˆå¤§å°å’Œé›œæ¹Šå€¼ï¼‰"""
    try:
        # ç²å–æ–‡ä»¶å¤§å°å’Œé›œæ¹Šå€¼
        cmd = [
            'ssh', '-i', SSH_KEY_PATH,
            '-o', 'ConnectTimeout=5',
            '-o', 'StrictHostKeyChecking=no',
            f'{REMOTE_USER}@{REMOTE_HOST}',
            f'if [ -f {REMOTE_DB_PATH} ]; then stat -c%s {REMOTE_DB_PATH} && md5sum {REMOTE_DB_PATH}; else echo "0"; echo "none none"; fi'
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            if len(lines) >= 2:
                size = int(lines[0])
                hash_value = lines[1].split()[0] if len(lines[1].split()) > 0 else "none"
                return size, hash_value
        return 0, None
    except Exception as e:
        logger.error(f"ç²å–é ç¨‹æ–‡ä»¶ä¿¡æ¯å¤±æ•—: {str(e)}")
        return 0, None

def get_local_file_info():
    """ç²å–æœ¬åœ°æ–‡ä»¶ä¿¡æ¯"""
    local_db = 'data/trading_signals.db'
    if not os.path.exists(local_db):
        return 0, None
    
    try:
        size = os.path.getsize(local_db)
        with open(local_db, 'rb') as f:
            hash_value = hashlib.md5(f.read()).hexdigest()
        return size, hash_value
    except:
        return 0, None

def read_last_sync_info():
    """è®€å–ä¸Šæ¬¡åŒæ­¥ä¿¡æ¯"""
    if not os.path.exists(HASH_FILE):
        return None, 0
    
    try:
        with open(HASH_FILE, 'r') as f:
            content = f.read().strip()
            if '|' in content:
                hash_value, size = content.split('|')
                return hash_value, int(size)
            else:
                return content, 0
    except:
        return None, 0

def save_sync_info(hash_value, size):
    """ä¿å­˜åŒæ­¥ä¿¡æ¯"""
    try:
        os.makedirs(os.path.dirname(HASH_FILE), exist_ok=True)
        with open(HASH_FILE, 'w') as f:
            f.write(f"{hash_value}|{size}")
    except Exception as e:
        logger.error(f"ä¿å­˜åŒæ­¥ä¿¡æ¯å¤±æ•—: {str(e)}")

def update_sync_stats(synced=False, saved_mb=0):
    """æ›´æ–°åŒæ­¥çµ±è¨ˆ"""
    try:
        stats = {'total_checks': 0, 'actual_syncs': 0, 'saved_mb': 0, 'last_check': ''}
        
        if os.path.exists(STATS_FILE):
            with open(STATS_FILE, 'r') as f:
                lines = f.readlines()
                for line in lines:
                    if '=' in line:
                        key, value = line.strip().split('=')
                        if key in ['total_checks', 'actual_syncs']:
                            stats[key] = int(value)
                        elif key == 'saved_mb':
                            stats[key] = float(value)
                        else:
                            stats[key] = value
        
        stats['total_checks'] += 1
        if synced:
            stats['actual_syncs'] += 1
        else:
            stats['saved_mb'] += saved_mb
        stats['last_check'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        with open(STATS_FILE, 'w') as f:
            for key, value in stats.items():
                f.write(f"{key}={value}\n")
                
        # è¨ˆç®—ç¯€çœæ¯”ä¾‹
        if stats['total_checks'] > 0:
            efficiency = ((stats['total_checks'] - stats['actual_syncs']) / stats['total_checks']) * 100
            logger.info(f"åŒæ­¥æ•ˆç‡: {efficiency:.1f}% (å·²ç¯€çœ {stats['saved_mb']:.1f}MB æµé‡)")
            
    except Exception as e:
        logger.error(f"æ›´æ–°çµ±è¨ˆå¤±æ•—: {str(e)}")

def main():
    """ä¸»è¦é‚è¼¯"""
    logger.info("ğŸ” æª¢æŸ¥é ç¨‹æ•¸æ“šæ˜¯å¦æœ‰è®ŠåŒ–...")
    
    # ç²å–æ–‡ä»¶ä¿¡æ¯
    remote_size, remote_hash = get_remote_file_info()
    local_size, local_hash = get_local_file_info()
    last_hash, last_size = read_last_sync_info()
    
    logger.info(f"é ç¨‹æ–‡ä»¶: {remote_size} bytes, hash: {remote_hash[:8] if remote_hash else 'None'}...")
    logger.info(f"æœ¬åœ°æ–‡ä»¶: {local_size} bytes, hash: {local_hash[:8] if local_hash else 'None'}...")
    
    # åˆ¤æ–·æ˜¯å¦éœ€è¦åŒæ­¥
    need_sync = False
    reason = ""
    
    if remote_hash is None:
        logger.warning("âš ï¸  ç„¡æ³•ç²å–é ç¨‹æ–‡ä»¶ä¿¡æ¯ï¼Œè·³éåŒæ­¥")
        update_sync_stats(synced=False, saved_mb=0)
        return
    
    if remote_hash == "none" or remote_size == 0:
        logger.info("ğŸ“Š é ç¨‹è³‡æ–™åº«ç‚ºç©ºï¼Œè·³éåŒæ­¥")
        update_sync_stats(synced=False, saved_mb=0)
        return
    
    if local_hash is None:
        need_sync = True
        reason = "æœ¬åœ°ç„¡è³‡æ–™åº«æ–‡ä»¶"
    elif remote_hash != last_hash:
        need_sync = True
        reason = "é ç¨‹æ•¸æ“šå·²æ›´æ–°"
    elif remote_size != last_size:
        need_sync = True
        reason = "æ–‡ä»¶å¤§å°å·²è®ŠåŒ–"
    
    if need_sync:
        logger.info(f"ğŸ”„ {reason}ï¼Œé–‹å§‹åŒæ­¥...")
        result = sync_database()
        
        if result['status'] == 'success':
            save_sync_info(remote_hash, remote_size)
            logger.info("âœ… åŒæ­¥å®Œæˆ")
            update_sync_stats(synced=True)
        else:
            logger.error(f"âŒ åŒæ­¥å¤±æ•—: {result['message']}")
            update_sync_stats(synced=False, saved_mb=0)
    else:
        # ä¼°ç®—ç¯€çœçš„æµé‡
        saved_mb = remote_size / 1024 / 1024
        logger.info(f"ğŸ“Š æ•¸æ“šç„¡è®ŠåŒ–ï¼Œè·³éåŒæ­¥ (ç¯€çœ {saved_mb:.2f}MB æµé‡)")
        update_sync_stats(synced=False, saved_mb=saved_mb)

if __name__ == '__main__':
    main()
